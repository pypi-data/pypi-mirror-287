{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pascal/zeitkapsel/.venv/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello|!| How| can| I| assist| you| today|?|I| am| an| AI| assistant| here| to| help| you| create| a| prompt| template|.| What| type| of| prompt| template| would| you| like| to| create|?|What| type| of| prompt| template| would| you| like| to| create|?| Please| provide| details| such| as| the| objective| of| the| prompt|,| variables| to| include|,| any| constraints|,| and| requirements|.|What| type| of| prompt| template| would| you| like| to| create|?| Please| provide| details| such| as| the| objective|,| variables|,| constraints|,| and| any| specific| requirements| you| have| in| mind|.|AI: Byebye\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain_core.messages import HumanMessage\n",
    "from main import graph\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "\n",
    "while True:\n",
    "    user = input(\"User (q/Q to quit): \")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "    async for output in graph.astream_events(\n",
    "        [HumanMessage(content=user)], config=config, version=\"v1\"\n",
    "    ):\n",
    "        kind = output[\"event\"]\n",
    "        if kind == \"on_chat_model_stream\":\n",
    "            content = output[\"data\"][\"chunk\"].content\n",
    "            if content:\n",
    "                print(content, end=\"|\")\n",
    "        elif kind == \"on_tool_start\":\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Starting tool: {output['name']} with inputs: {output['data'].get('input')}\"\n",
    "            )\n",
    "        elif kind == \"on_tool_end\":\n",
    "            print(f\"Done tool: {output['name']}\")\n",
    "            print(f\"Tool output was: {output['data'].get('output')}\")\n",
    "            print(\"--\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
