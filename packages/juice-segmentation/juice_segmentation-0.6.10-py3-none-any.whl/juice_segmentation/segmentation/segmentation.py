"""
Created on May 2021

@author: Claudio Munoz Crego (ESAC)

This module allows to generate a Segmentation Proposal File (SCHE_0010)
from an Opportunity timeline file


    0) We start loading and parsing json file
        0.1) Segmentation Opportunities timeline (generated by user from SHT)
        0.2) Segmentation Definition get via REST-API
        Note: To perform this the corresponding path must be set-up

    1) Define environment parameter
    2) Define parameters, input and output path
    3) Select original segments per working group
    4) Set-up Metrics for reporting using original segments before any cut
    5) Select Calibration
    5) Select Calibration
    6) Combine WG according to given priority rules
    7) Allocating Juice Moon OPE_NAV for FD and WG3 (and WG4, WG2 if needed)
    8) Generating segmentation and metric report

"""

import logging
import os
import sys

from juice_segmentation.commons.mission_timeline_event_file_handler import MissionTimelineEvent
from juice_segmentation.commons.segment_handler import SegmentHandler
from juice_segmentation.wg.wg_segmentation import WgSegmentation
from juice_segmentation.wg.wg_utils import json_str_2_datatime


def generate_proposal_file(input_segmentation_file_path, output_dir_path, config, create_csv=True,
                           wg_segments_to_ignore=[]):
    """
    Generate a Juice Segmentation Proposal File (SCHE_0010)
    from a Segmentation Opportunities timeline

    :param wg_segments_to_ignore: Working group - segment to be ignored
    :param input_segmentation_file_path: segmentation Opportunities timeline file path (json)
    :param output_dir_path: output directory path (must exits)
    :param config: configuration parameters
    :param create_csv: Flag allowing to create orginale working group segment files; default=true
    """

    check_input_path(input_segmentation_file_path, output_dir_path)

    #
    # 0) Load and parse Segmentation Opportunities timeline & Segmentation Definition
    # and generate a csv working group segment file corresponding to Segmentation Opportunities timeline (name wg_all)
    #

    seg_all_json_file_path = input_segmentation_file_path

    wg_all_original_segment_file = os.path.join(output_dir_path, 'wg_all.csv')

    start = None
    if 'start' in config.keys():
        if 'start' != '':
            start = json_str_2_datatime(config['start'])
            if start is None:
                logging.error('bad start time in config (expected format is %Y-%m-%dT%H:%M:%SZ"): {}'.format(
                    config['start']))
                sys.exit()
    end = None
    if 'end' in config.keys():
        if 'end' != '':
            end = json_str_2_datatime(config['end'])
            if end is None:
                logging.error('bad end time in config (expected format is %Y-%m-%dT%H:%M:%SZ"): {}'.format(
                    config['end']))
                sys.exit()
            elif start is not None:
                if end <= start:
                    logging.error('end must be > start; Check config: (start,end) = ({}, {})'.format(start, end))
                    sys.exit()

    segment_handler = SegmentHandler(seg_all_json_file_path, wg_segments_to_ignore=wg_segments_to_ignore,
                                     start=start, end=end)

    #
    # 1) Define environment parameter
    #

    crema_id = str(config['crema_id']).lower()
    # pass crema_id
    segment_handler.create_csv_segment_file(wg_csv_file_path=wg_all_original_segment_file, crema_id=crema_id)

    wg_seg_input = [wg_all_original_segment_file]
    if "wg_seg_input" in config.keys():
        wg_seg_input = wg_seg_input + config["wg_seg_input"]

    juice_conf = config["juice_conf"]
    if "mission_phases" in config.keys():
        mission_phases = config["mission_phases"]
    else:
        mission_phases = os.path.join(juice_conf, 'internal', 'geopipeline', 'output', crema_id, 'Mission_Phases.csv')

    if "mission_timeline_event_file" in config.keys():
        mission_timeline_event_file = config["mission_timeline_event_file"]
    else:
        [crema_id_x, crema_id_y] = crema_id.replace('crema_', '').split('_')
        mission_timeline_event_file_name = 'mission_timeline_event_file_{}_{}.csv'.format(crema_id_x, crema_id_y)
        mission_timeline_event_file = os.path.join(juice_conf, 'internal', 'geopipeline', 'output',
                                                   crema_id, mission_timeline_event_file_name)

    if "opportunity_vs_prime" in config.keys():
        opportunity_vs_prime = config["opportunity_vs_prime"]
    else:
        opportunity_vs_prime = os.path.join(juice_conf, *['internal', 'segmentation_scheduler', 'input', 'conf',
                                                          'OPPORTUNITY_PRIME_correspondance.csv'])

    #
    # 2) Define parameters, input and output path
    #   - root_path: is the local base directory use as default directory for inputs (we will use outputdir)
    #   - wg_seg_input: contains the list of csv files including segment detail.
    #     This list contain wg_all generate in 0) and do not need to be changed
    #   - mission_phases: path to the trajectory dependent file "Mission_Phases.csv"
    #   - mission_timeline_event_file: path to the trajectory dependent file "mission_timeline_event_file_X_Y.csv"
    #   - opportunity_vs_prime: path to the OPPORTUNITY_PRIME_correspondance.csv file
    #

    json_data = \
        {
            "root_path": output_dir_path,
            "output": {"dir": output_dir_path,
                       "file_prefix": "segmentation_proposal_" + crema_id, "file_sufix": ".csv",
                       "file_prefix_origin": "segmentation_opportunities_" + crema_id, "file_sufix_origin": ".csv"},
            "wg_seg_input": wg_seg_input,
            "mission_phases": mission_phases,
            "mission_timeline_event_file": mission_timeline_event_file,
            "opportunity_vs_prime": opportunity_vs_prime,
            "calib_roll": config['calib_roll']
        }

    #
    # 3) Select original segments per working group
    # For instance:
    # - From wg1, we select segment with name including '_FLYBY_GALA'
    # - From wgx, we select all the 'JMAG_CALROLL' and 'SUN_CONJUNCTION_SUP'
    # - We get FD from GENERIC working group
    #

    juice_seg = WgSegmentation(json_data)
    sun_conjunction = MissionTimelineEvent(juice_seg.config.mission_timeline_event_file).get_sun_conjunctions()
    wgx_sun_conjunction = {'WGX': sun_conjunction}
    seg = juice_seg.seg

    wg_seg = seg.get_original_wg_seg(juice_seg.config)

    seg_to_load = config["seg_to_load"]

    wg1 = {'WG1': {}}
    wg2 = {'WG2': {}}
    wg3 = {'WG3': {}}
    wg4 = {'WG4': {}}
    wgx = {'WGX': {}}
    dl_ = {'GENERIC': {}}
    fd_nav = {'GENERIC': {}}
    fd_tcm = {'GENERIC': {}}
    fd_wol = {'GENERIC': {}}

    fd_ope_nav = seg.select_wgx_subset(wg_seg, wg_filter=['GENERIC'], seg_filter=["OPNAV_"])

    ids = range(len(seg_to_load))
    ws = []
    for i in ids:

        [wg_i, seg_i] = seg_to_load[i]
        print([wg_i, seg_i])

        ws.append(seg.select_wgx_subset(wg_seg, wg_filter=[wg_i], seg_filter=seg_i))

        # if 'JUPITER_MONITORING' in seg_i: Work-around to remove JUPITER_MONITORING overlaps
        #
        #     ws[i] = seg.merge_wgx_segments(ws[i], ws[i])
        #
        #     # p = IntervalHandlers()
        #     # tmp = ws[i][wg_i]['JUPITER_MONITORING']
        #     # ws[i][wg_i]['JUPITER_MONITORING'] = p.merge_intervals(ws[i][wg_i]['JUPITER_MONITORING'])

        if wg_i == "WG1":
            wg1 = seg.merge_wgx_segments(wg1, ws[i])
        elif wg_i == 'WG2':
            wg2 = seg.merge_wgx_segments(wg2, ws[i])
        elif wg_i == 'WG3':
            wg3 = seg.merge_wgx_segments(wg3, ws[i])
        elif wg_i == 'WG4':
            wg4 = seg.merge_wgx_segments(wg4, ws[i])
        elif wg_i == 'WGX':
            wgx = seg.merge_wgx_segments(wgx, ws[i])
        elif wg_i == 'GENERIC' and 'DL_' in seg_i:
            dl_ = seg.merge_wgx_segments(dl_, ws[i])
        elif wg_i == 'GENERIC' and 'JUPITER_FD_TCM' in seg_i:
            fd_tcm = seg.merge_wgx_segments(fd_tcm, ws[i])
        elif wg_i == 'GENERIC' and ('JUPITER_FD_WOL' in seg_i or 'JUPITER_FD_WOL_FB' in seg_i):
            fd_wol = seg.merge_wgx_segments(fd_wol, ws[i])
        else:
            logging.error('cannot catch working group segment: {}, {}'.format(wg_i, seg_i))
            sys.exit()

    #
    #  4) Set-up Metrics for reporting using original segments before any cut
    #
    juice_seg.set_original_metrics(wg1, wg2, wg3, wg4, wgx, dl_, fd_nav, fd_tcm, fd_wol, fd_ope_nav,
                                   create_csv=create_csv)

    #
    #  5) Select Calibration (using Mission_Phases.cvs labels)
    #

    wgx_calib = juice_seg.get_wgx_cal_roll(wgx, config['calib_roll'])
    wgx_calib_original = seg.select_wgx_subset(wg_seg, wg_filter=["WGX"], seg_filter=['JMAG_CALROLL'])

    #
    # 6) Combine WG according to given priority rules
    # Decreasing priority order for scheduling
    #

    for i in ids:

        if ws[i]:

            wg_to_substract = [ws[k] for k in ids if k < i]

            segment_minimun_sec = 60
            wg_i = list(ws[i].keys())[0]
            seg_i = list(ws[i][wg_i].keys())
            if 'DL_' in seg_i:
                segment_minimun_sec = 3 * 3600

            if 'WG3' in wg_i:
                segment_minimun_sec = 0

            if 'JMAG_CALROLL' in seg_i:
                del (ws[i][wg_i]['JMAG_CALROLL'])
                ws[i] = seg.wg_substract(ws[i], [wgx_calib_original])
                ws[i] = seg.merge_wgx_segments(ws[i], wgx_calib)

            ws[i] = seg.wg_substract(ws[i], wg_to_substract, segment_minimun_sec=segment_minimun_sec)

    wg1 = {'WG1': {}}
    wg2 = {'WG2': {}}
    wg3 = {'WG3': {}}
    wg4 = {'WG4': {}}
    wgx = {'WGX': {}}
    dl_ = {'GENERIC': {}}
    fd_nav = {'GENERIC': {}}
    fd_tcm = {'GENERIC': {}}
    fd_wol = {'GENERIC': {}}

    ids = range(len(seg_to_load))
    for i in ids:

        [wg_i, seg_i] = seg_to_load[i]

        if wg_i == "WG1":
            wg1 = seg.merge_wgx_segments(wg1, ws[i])
        elif wg_i == 'WG2':
            wg2 = seg.merge_wgx_segments(wg2, ws[i])
        elif wg_i == 'WG3':
            wg3 = seg.merge_wgx_segments(wg3, ws[i])
        elif wg_i == 'WG4':
            wg4 = seg.merge_wgx_segments(wg4, ws[i])
        elif wg_i == 'WGX':
            wgx = seg.merge_wgx_segments(wgx, ws[i])
        elif wg_i == 'GENERIC' and 'DL_' in seg_i:
            dl_ = seg.merge_wgx_segments(dl_, ws[i])
        elif wg_i == 'GENERIC' and 'JUPITER_FD_TCM' in seg_i:
            fd_tcm = seg.merge_wgx_segments(fd_tcm, ws[i])
        elif wg_i == 'GENERIC' and ('JUPITER_FD_WOL' in seg_i or 'JUPITER_FD_WOL_FB' in seg_i):
            fd_wol = seg.merge_wgx_segments(fd_wol, ws[i])
        else:
            logging.error('cannot catch working group segment: {}, {}'.format(wg_i, seg_i))
            sys.exit()

    #
    # 7) Allocating Juice Moon OPE_NAV for FD and WG3 (and WG4, WG2 if needed)
    #
    op_nav_insertion_rules = config["op_nav_insertion_rules"]

    fd_openav_selected, wg1, wg2, wg3, wg4, wgx, fd_tcm, fd_wol, dl_ = \
        juice_seg.schedule_ope_nav_4(wg1, wg2, wg3, wg4, wgx, fd_tcm, fd_wol, dl_, fd_ope_nav, wgx_sun_conjunction,
                                     fd_nav, op_nav_insertion_rules)
    #   juice_seg.schedule_ope_nav_4(wg1, wg2, wg3, wg4, wgx, fd_tcm, fd_wol, dl_, fd_ope_nav, wgx_sun_conjunction,
    #                                    fd_nav)

    wg_all = seg.wg_add(wgx, [fd_openav_selected, wg1, wg2, wg3, wg4, fd_nav, fd_tcm, fd_wol, dl_])

    #
    # 8) Generating segmentation and metric report
    #

    juice_seg.generate_segment_and_report(wg1, wg2, wg3, wg4, wgx,
                                          dl_, fd_nav, fd_tcm, fd_wol, fd_openav_selected, wg_all,
                                          segment_handler=segment_handler,
                                          generate_report=True,
                                          create_csv=create_csv)

    if not create_csv:  # then remove 'wg_all.csv' the csv version of input_segmentation_file

        os.remove(wg_all_original_segment_file)


def check_input_path(input_segmentation_file_path, output_dir_path):
    if not os.path.exists(input_segmentation_file_path):
        logging.error('input_segmentation_file_path does not exist: {}'.format(input_segmentation_file_path))
        sys.exit(0)
    elif not os.path.isfile(input_segmentation_file_path):
        logging.error('input_segmentation_file_path is not a file: {}'.format(input_segmentation_file_path))
        sys.exit(0)

    if not os.path.exists(output_dir_path):
        logging.error('output_dir_path does not exist: {}'.format(output_dir_path))
        logging.info('Please, create the corresponding directory')
        sys.exit(0)
    elif not os.path.isdir(output_dir_path):
        logging.error('output_dir_path is not a directory: {}'.format(output_dir_path))
        sys.exit(0)
