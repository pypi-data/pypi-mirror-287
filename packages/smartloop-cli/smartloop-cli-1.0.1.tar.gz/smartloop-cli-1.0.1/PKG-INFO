Metadata-Version: 2.1
Name: smartloop-cli
Version: 1.0.1
Summary: Smartloop Command Line interface to process documents using LLM
Home-page: https://github.com/SmartloopHQ/smartloop-cl
Author: Smartloop Inc.
Author-email: mehfuz@smartloop.ai
License: LICENSE.txt
Keywords: LLM,framework,llama3,phi3,platform
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Description-Content-Type: text/markdown
License-File: LICENSE.txt

# Smartloop Command Line Interface

Smartloop CLI to upload, managed and chat with documents fine-tuned using foundational LLM models. It uses the smartloop API to manage projects and documents and gives you quickly process contents using LLM and test

## Requirements

- Python 3.11

## Getting Started

Install the CLI with the following command:

```
pip install -U smartloop-cli

```
Once install, check that everything is setup correclty:


```
$ smartloop-cli --help

 Usage: main.py [OPTIONS] COMMAND [ARGS]...

│ login     Login using a token from https://api.smartloop.ai/v1/redoc                                                                                                            │
│ project                                                                                                                                                                         │
│ run       Starts a chat session with a selected project                                                                                                                         │
│ upload    Upload documents for a slected project                                                                                                                                │
│ whoami    Find out which account you are logged in


```

## Creating Account

Create an account using the smartloop API in the following way:


```
curl --location --request PUT 'https://api.smartloop.ai/v1/users' \
--header 'Content-Type: application/json' \
--header 'Accept: application/json' \
--data '{
  "email": "<string>",
  "password": "<string>",
  "name": "<string>",
  "username": "<string>",
  "notify": true
}'
```


Please email us a hello@smartloop.ai to verify your account. 


## Generating Token

Once verified, create a token:


```
curl --location --request PUT 'https://api.smartloop.ai/v1/users/tokens' \
--header 'Content-Type: application/json' \
--header 'Accept: application/json' \
--header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6Im1laGZ1ekBzbWFydGxvb3AuYWkifQ.VMKK1fXfjQfd2-0aFBdtL2HIPsyNzKeeLKXHuEQY7A4' \
--data '{
  "name": "smartloop-cli"
}'

```

## Setting up the CLI

Login to the CLI in the follwoing way:

```
smartloop-cli login
```

This command will prompt you for token, copy and pase the token that you have generated using the command above

```
$ python main.py login
                       _    _
 ___ _ __   __ _  _ _ | |_ | | ___  ___  _ __
(_-<| '  \ / _` || '_||  _|| |/ _ \/ _ \| '_ \ _
/__/|_|_|_|\__,_||_|   \__||_|\___/\___/| .__/(_)
                                        |_|

You can generatate your token from /users/token endpoint
Enter your token (Token will be invisitble):

```


Next step it to create  project, you can do so with following command:

```
smartloop-cli project create --name Lexic
```

## Upload Document

Once the project is create , upload document from your folder or a file:

```
smartloop-cli upload --file=~/OnlineSvcsConsolidatedSLA\(WW\)\(English\)\(June2024\)\(CR\).docx
```

## Run It

Finally, once document is upload and processed, start asking question by issuing the following command:

```
smartloop-cli run
```

This will brin up the following interface:

```
$ smartloop-cli run
Current project: Microsoft(microsoft-24-07-2024)
Enter message (Ctrl-C to exit): what the SLA for azure open ai
⠋
The SLA (Service Level Agreement) for Azure OpenAI is not explicitly mentioned in the provided text. However, it's possible that the SLA for Azure OpenAI might be similar to the one mentioned below:

"Uptime Percentage"

* Service Credit:
+ < 99.9%: 10%
+ < 99%: 25%
+ < 95%: 100%

Please note that this is not a direct quote from the provided text, but rather an inference based on the format and structure of the SLA mentioned for other Azure services (e.g., SAP HANA on Azure High Availability Pair). To confirm the actual SLA for Azure OpenAI, you should check the official Microsoft documentation or contact their support team.

Enter message (Ctrl-C to exit):
```

# Contributing

Contributions are welcome! Please create a pull request with your changes.


# Contact

If you have any questions or suggestions, please feel free to reach out to hello@smartloop.ai


# References

* [Smartloop API Documentation](https://api.smartloop.ai/v1/redoc)

