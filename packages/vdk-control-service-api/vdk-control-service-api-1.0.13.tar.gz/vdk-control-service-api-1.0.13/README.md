# vdk-control-service-api
The Data Jobs API of Versatile Data Kit Control Service. Data Jobs allows Data Engineers to implement automated pull ingestion (E in ELT) and batch data transformation into a database (T in ELT). See also https://github.com/vmware/versatile-data-kit/wiki/Introduction
The API has resource-oriented URLs, JSON-encoded responses, and uses standard HTTP response codes, authentication, and verbs. The API enables creating, deploying, managing and executing Data Jobs in the runtime environment.<br> <br> ![](https://github.com/vmware/versatile-data-kit/wiki/vdk-data-job-lifecycle-state-diagram.png) <br> The API reflects the usual Data Job Development lifecycle:<br> <li> Create a new data job (webhook to further configure the job, e.g authorize its creation, setup permissions, etc). <li> Download keytab. Develop and run the data job locally. <li> Deploy the data job in cloud runtime environment to run on a scheduled basis. <br><br> If Authentication is enabled, pass OAuth2 access token in HTTP header 'Authorization: Bearer [access-token-here]' (https://datatracker.ietf.org/doc/html/rfc6750). <br
The API promotes some best practices (inspired by https://12factor.net): <li> Explicitly declare and isolate dependencies. <li> Strict separation of configurations from code. Configurations vary substantially across deploys, code does not. <li> Separation between the build, release/deploy, and run stages. <li> Data Jobs are stateless and share-nothing processes. Any data that needs to be persisted must be stored in a stateful backing service (e.g IProperties). <li> Implementation is assumed to be atomic and idempotent - should be OK for a job to fail somewhere in the middle; subsequent restart should not cause data corruption. <li> Keep development, staging, and production as similar as possible. <br><br> <b>API Evolution</b><br> In the following sections, there are some terms that have a special meaning in the context of the APIs. <br><br> <li> <i>Stable</i> - The implementation of the API has been battle-tested (has been in production for some time). The API is a subject to semantic versioning model and will follow deprecation policy. <li> <i>Experimental</i> - May disappear without notice and is not a subject to semantic versioning. Implementation of the API is not considered stable nor well tested. Generally this is given to clients to experiment within testing environment. Must not be used in production. <li> <i>Deprecated</i> - API is expected to be removed within next one or two major version upgrade. The deprecation notice/comment will say when the API will be removed and what alternatives should be used instead.

This Python package is automatically generated by the [OpenAPI Generator](https://openapi-generator.tech) project:

- API version: 1.0
- Package version: 1.0.13
- Build package: org.openapitools.codegen.languages.PythonNextgenClientCodegen

## Requirements.

Python 3.7+

## Installation & Usage
### pip install

If the python package is hosted on a repository, you can install directly using:

```sh
pip install git+https://github.com/GIT_USER_ID/GIT_REPO_ID.git
```
(you may need to run `pip` with root permission: `sudo pip install git+https://github.com/GIT_USER_ID/GIT_REPO_ID.git`)

Then import the package:
```python
import taurus_datajob_api
```

### Setuptools

Install via [Setuptools](http://pypi.python.org/pypi/setuptools).

```sh
python setup.py install --user
```
(or `sudo python setup.py install` to install the package for all users)

Then import the package:
```python
import taurus_datajob_api
```

### Tests

Execute `pytest` to run the tests.

## Getting Started

Please follow the [installation procedure](#installation--usage) and then run the following:

```python

import time
import taurus_datajob_api
from taurus_datajob_api.rest import ApiException
from pprint import pprint

# Defining the host is optional and defaults to http://localhost:8092
# See configuration.py for a list of all supported configuration parameters.
configuration = taurus_datajob_api.Configuration(
    host = "http://localhost:8092"
)

# The client must configure the authentication and authorization parameters
# in accordance with the API server security policy.
# Examples for each auth method are provided below, use the example that
# satisfies your auth use case.

# Configure Bearer authorization (JWT): bearerAuth
configuration = taurus_datajob_api.Configuration(
    access_token = os.environ["BEARER_TOKEN"]
)


# Enter a context with an instance of the API client
with taurus_datajob_api.ApiClient(configuration) as api_client:
    # Create an instance of the API class
    api_instance = taurus_datajob_api.DataJobsApi(api_client)
    team_name = 'team_name_example' # str | The Team which owns the Data Job
    data_job = taurus_datajob_api.DataJob() # DataJob | 
    name = 'name_example' # str | The Name of the Data Job (optional)

    try:
        # Creates a new Data Job | (Stable)
        api_instance.data_job_create(team_name, data_job, name=name)
    except ApiException as e:
        print("Exception when calling DataJobsApi->data_job_create: %s\n" % e)

```

## Documentation for API Endpoints

All URIs are relative to *http://localhost:8092*

Class | Method | HTTP request | Description
------------ | ------------- | ------------- | -------------
*DataJobsApi* | [**data_job_create**](docs/DataJobsApi.md#data_job_create) | **POST** /data-jobs/for-team/{team_name}/jobs | Creates a new Data Job | (Stable)
*DataJobsApi* | [**data_job_delete**](docs/DataJobsApi.md#data_job_delete) | **DELETE** /data-jobs/for-team/{team_name}/jobs/{job_name} | Delete Data Job | (Stable)
*DataJobsApi* | [**data_job_keytab_download**](docs/DataJobsApi.md#data_job_keytab_download) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/keytab | Get data job keytab. | (Stable)
*DataJobsApi* | [**data_job_read**](docs/DataJobsApi.md#data_job_read) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name} | Retrieves details of an existing Data Job by specifying the name of the Data Job. | (Stable)
*DataJobsApi* | [**data_job_team_update**](docs/DataJobsApi.md#data_job_team_update) | **PUT** /data-jobs/for-team/{team_name}/jobs/{job_name}/team/{new_team} | Update API for Data Jobs team | (Stable)
*DataJobsApi* | [**data_job_update**](docs/DataJobsApi.md#data_job_update) | **PUT** /data-jobs/for-team/{team_name}/jobs/{job_name} | Update Data Job. | (Stable)
*DataJobsApi* | [**jobs_query**](docs/DataJobsApi.md#jobs_query) | **GET** /data-jobs/for-team/{team_name}/jobs | Query Data Jobs details using GraphQL
*DataJobsDeploymentApi* | [**deployment_delete**](docs/DataJobsDeploymentApi.md#deployment_delete) | **DELETE** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id} | Delete Deployment of a Data Job. Currently executing Data Job will be left to finish.  | (Stable) 
*DataJobsDeploymentApi* | [**deployment_list**](docs/DataJobsDeploymentApi.md#deployment_list) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments | Get Data Job deployments. | (Stable)
*DataJobsDeploymentApi* | [**deployment_patch**](docs/DataJobsDeploymentApi.md#deployment_patch) | **PATCH** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id} | Patch a deployment of a Data Job. Use it to change the configuration of a data job. For example: to enable or disable deployment, to change the vdk version. The operation is guranteed to be synchrounous so it cannot be used to deploy new version of a data job - job_version cannot be changed using PATCH. Use POST .../deployments for this. | (Stable) 
*DataJobsDeploymentApi* | [**deployment_read**](docs/DataJobsDeploymentApi.md#deployment_read) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id} | Get Data Job deployments. | (Stable)
*DataJobsDeploymentApi* | [**deployment_update**](docs/DataJobsDeploymentApi.md#deployment_update) | **POST** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments | Creates or updates a deployment of a Data Job. | (Stable)
*DataJobsExecutionApi* | [**data_job_deployment_execution_list**](docs/DataJobsExecutionApi.md#data_job_deployment_execution_list) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id}/executions | Get Data Jobs (recent) executions.
*DataJobsExecutionApi* | [**data_job_execution_cancel**](docs/DataJobsExecutionApi.md#data_job_execution_cancel) | **DELETE** /data-jobs/for-team/{team_name}/jobs/{job_name}/executions/{execution_id} | Cancel (if running) Data Job Execution
*DataJobsExecutionApi* | [**data_job_execution_list**](docs/DataJobsExecutionApi.md#data_job_execution_list) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/executions | Get Data Jobs (recent) executions.
*DataJobsExecutionApi* | [**data_job_execution_read**](docs/DataJobsExecutionApi.md#data_job_execution_read) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/executions/{execution_id} | Get Data Job Execution details.
*DataJobsExecutionApi* | [**data_job_execution_start**](docs/DataJobsExecutionApi.md#data_job_execution_start) | **POST** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id}/executions | Trigger Data Job Execution.
*DataJobsExecutionApi* | [**data_job_logs_download**](docs/DataJobsExecutionApi.md#data_job_logs_download) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/executions/{execution_id}/logs | Download data job logs. This API is guranteed to provide logs only if the jobs is currently running. For logs from older job executions - use logsUrl field passed by GET execution API or jobsQuery API. 
*DataJobsPropertiesApi* | [**data_job_properties_read**](docs/DataJobsPropertiesApi.md#data_job_properties_read) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id}/properties | Get Data Job properties.
*DataJobsPropertiesApi* | [**data_job_properties_update**](docs/DataJobsPropertiesApi.md#data_job_properties_update) | **PUT** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id}/properties | Update Data Job properties.
*DataJobsSecretsApi* | [**client_id_get**](docs/DataJobsSecretsApi.md#client_id_get) | **GET** /data-jobs/teams/{team_name}/oauth-credentials/client-id | Retrieve the OAuth client ID for a specific team identified by {team_name}. | (Stable)
*DataJobsSecretsApi* | [**data_job_secrets_read**](docs/DataJobsSecretsApi.md#data_job_secrets_read) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id}/secrets | Get Data Job secrets.
*DataJobsSecretsApi* | [**data_job_secrets_update**](docs/DataJobsSecretsApi.md#data_job_secrets_update) | **PUT** /data-jobs/for-team/{team_name}/jobs/{job_name}/deployments/{deployment_id}/secrets | Update Data Job secrets.
*DataJobsSecretsApi* | [**get_team_ids_for_client_ids**](docs/DataJobsSecretsApi.md#get_team_ids_for_client_ids) | **POST** /data-jobs/oauth-credentials/client-ids | for a given list of ClientID(s) return a list of Team Ids,e.g. list of [clientId:teamId,clientId1:teamID1]
*DataJobsSecretsApi* | [**oauth_credentials_get**](docs/DataJobsSecretsApi.md#oauth_credentials_get) | **GET** /data-jobs/teams/{team_name}/oauth-credentials | Get the Team&#39;s Oauth Application Credentials. | (Stable)
*DataJobsSecretsApi* | [**oauth_credentials_put**](docs/DataJobsSecretsApi.md#oauth_credentials_put) | **PUT** /data-jobs/teams/{team_name}/oauth-credentials | Creates or updates a Team&#39;s Oauth Application Credentials. | (Stable)
*DataJobsServiceApi* | [**info**](docs/DataJobsServiceApi.md#info) | **GET** /data-jobs/for-team/{team_name}/info | Get API and Data Jobs Service info, list of supported python versions
*DataJobsSourcesApi* | [**data_job_sources_download**](docs/DataJobsSourcesApi.md#data_job_sources_download) | **GET** /data-jobs/for-team/{team_name}/jobs/{job_name}/sources | Download data job source code. | (Not Implemented)
*DataJobsSourcesApi* | [**sources_delete**](docs/DataJobsSourcesApi.md#sources_delete) | **DELETE** /data-jobs/for-team/{team_name}/jobs/{job_name}/sources | Delete Data Job source.
*DataJobsSourcesApi* | [**sources_upload**](docs/DataJobsSourcesApi.md#sources_upload) | **POST** /data-jobs/for-team/{team_name}/jobs/{job_name}/sources | Upload Data Job source code. | (Stable)


## Documentation For Models

 - [DataJob](docs/DataJob.md)
 - [DataJobApiInfo](docs/DataJobApiInfo.md)
 - [DataJobConfig](docs/DataJobConfig.md)
 - [DataJobContacts](docs/DataJobContacts.md)
 - [DataJobDeployment](docs/DataJobDeployment.md)
 - [DataJobDeploymentStatus](docs/DataJobDeploymentStatus.md)
 - [DataJobExecution](docs/DataJobExecution.md)
 - [DataJobExecutionLogs](docs/DataJobExecutionLogs.md)
 - [DataJobExecutionRequest](docs/DataJobExecutionRequest.md)
 - [DataJobMode](docs/DataJobMode.md)
 - [DataJobPage](docs/DataJobPage.md)
 - [DataJobQueryResponse](docs/DataJobQueryResponse.md)
 - [DataJobQueryResponseWithError](docs/DataJobQueryResponseWithError.md)
 - [DataJobResources](docs/DataJobResources.md)
 - [DataJobSchedule](docs/DataJobSchedule.md)
 - [DataJobSummary](docs/DataJobSummary.md)
 - [DataJobVersion](docs/DataJobVersion.md)
 - [Error](docs/Error.md)
 - [OauthCredentials](docs/OauthCredentials.md)
 - [OauthTeamClientId](docs/OauthTeamClientId.md)
 - [OauthTeamCredentials](docs/OauthTeamCredentials.md)


<a id="documentation-for-authorization"></a>
## Documentation For Authorization


Authentication schemes defined for the API:
<a id="bearerAuth"></a>
### bearerAuth

- **Type**: Bearer authentication (JWT)


## Author




