# coding: utf-8

"""
    Versatile Data Kit Control Service API

    The Data Jobs API of Versatile Data Kit Control Service. Data Jobs allows Data Engineers to implement automated pull ingestion (E in ELT) and batch data transformation into a database (T in ELT). See also https://github.com/vmware/versatile-data-kit/wiki/Introduction The API has resource-oriented URLs, JSON-encoded responses, and uses standard HTTP response codes, authentication, and verbs. The API enables creating, deploying, managing and executing Data Jobs in the runtime environment.<br> <br> ![](https://github.com/vmware/versatile-data-kit/wiki/vdk-data-job-lifecycle-state-diagram.png) <br> The API reflects the usual Data Job Development lifecycle:<br> <li> Create a new data job (webhook to further configure the job, e.g authorize its creation, setup permissions, etc). <li> Download keytab. Develop and run the data job locally. <li> Deploy the data job in cloud runtime environment to run on a scheduled basis. <br><br> If Authentication is enabled, pass OAuth2 access token in HTTP header 'Authorization: Bearer [access-token-here]' (https://datatracker.ietf.org/doc/html/rfc6750). <br The API promotes some best practices (inspired by https://12factor.net): <li> Explicitly declare and isolate dependencies. <li> Strict separation of configurations from code. Configurations vary substantially across deploys, code does not. <li> Separation between the build, release/deploy, and run stages. <li> Data Jobs are stateless and share-nothing processes. Any data that needs to be persisted must be stored in a stateful backing service (e.g IProperties). <li> Implementation is assumed to be atomic and idempotent - should be OK for a job to fail somewhere in the middle; subsequent restart should not cause data corruption. <li> Keep development, staging, and production as similar as possible. <br><br> <b>API Evolution</b><br> In the following sections, there are some terms that have a special meaning in the context of the APIs. <br><br> <li> <i>Stable</i> - The implementation of the API has been battle-tested (has been in production for some time). The API is a subject to semantic versioning model and will follow deprecation policy. <li> <i>Experimental</i> - May disappear without notice and is not a subject to semantic versioning. Implementation of the API is not considered stable nor well tested. Generally this is given to clients to experiment within testing environment. Must not be used in production. <li> <i>Deprecated</i> - API is expected to be removed within next one or two major version upgrade. The deprecation notice/comment will say when the API will be removed and what alternatives should be used instead.  # noqa: E501

    The version of the OpenAPI document: 1.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""


import re  # noqa: F401
import io
import warnings

from pydantic import validate_arguments, ValidationError
from typing_extensions import Annotated

from pydantic import Field, StrictBytes, StrictStr

from typing import Optional, Union

from taurus_datajob_api.models.data_job_version import DataJobVersion

from taurus_datajob_api.api_client import ApiClient
from taurus_datajob_api.api_response import ApiResponse
from taurus_datajob_api.exceptions import (  # noqa: F401
    ApiTypeError,
    ApiValueError
)


class DataJobsSourcesApi(object):
    """NOTE: This class is auto generated by OpenAPI Generator
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    def __init__(self, api_client=None):
        if api_client is None:
            api_client = ApiClient.get_default()
        self.api_client = api_client

    @validate_arguments
    def data_job_sources_download(self, team_name : Annotated[StrictStr, Field(..., description="Team Name")], job_name : Annotated[StrictStr, Field(..., description="Data Job Name.")], **kwargs) -> bytearray:  # noqa: E501
        """Download data job source code. | (Not Implemented)  # noqa: E501

        <i>(Introduced in v1.0)</i>  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True

        >>> thread = api.data_job_sources_download(team_name, job_name, async_req=True)
        >>> result = thread.get()

        :param team_name: Team Name (required)
        :type team_name: str
        :param job_name: Data Job Name. (required)
        :type job_name: str
        :param async_req: Whether to execute the request asynchronously.
        :type async_req: bool, optional
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return: Returns the result object.
                 If the method is called asynchronously,
                 returns the request thread.
        :rtype: bytearray
        """
        kwargs['_return_http_data_only'] = True
        if '_preload_content' in kwargs:
            raise ValueError("Error! Please call the data_job_sources_download_with_http_info method with `_preload_content` instead and obtain raw data from ApiResponse.raw_data")
        return self.data_job_sources_download_with_http_info(team_name, job_name, **kwargs)  # noqa: E501

    @validate_arguments
    def data_job_sources_download_with_http_info(self, team_name : Annotated[StrictStr, Field(..., description="Team Name")], job_name : Annotated[StrictStr, Field(..., description="Data Job Name.")], **kwargs) -> ApiResponse:  # noqa: E501
        """Download data job source code. | (Not Implemented)  # noqa: E501

        <i>(Introduced in v1.0)</i>  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True

        >>> thread = api.data_job_sources_download_with_http_info(team_name, job_name, async_req=True)
        >>> result = thread.get()

        :param team_name: Team Name (required)
        :type team_name: str
        :param job_name: Data Job Name. (required)
        :type job_name: str
        :param async_req: Whether to execute the request asynchronously.
        :type async_req: bool, optional
        :param _preload_content: if False, the ApiResponse.data will
                                 be set to none and raw_data will store the 
                                 HTTP response body without reading/decoding.
                                 Default is True.
        :type _preload_content: bool, optional
        :param _return_http_data_only: response data instead of ApiResponse
                                       object with status code, headers, etc
        :type _return_http_data_only: bool, optional
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the authentication
                              in the spec for a single request.
        :type _request_auth: dict, optional
        :type _content_type: string, optional: force content-type for the request
        :return: Returns the result object.
                 If the method is called asynchronously,
                 returns the request thread.
        :rtype: tuple(bytearray, status_code(int), headers(HTTPHeaderDict))
        """

        _params = locals()

        _all_params = [
            'team_name',
            'job_name'
        ]
        _all_params.extend(
            [
                'async_req',
                '_return_http_data_only',
                '_preload_content',
                '_request_timeout',
                '_request_auth',
                '_content_type',
                '_headers'
            ]
        )

        # validate the arguments
        for _key, _val in _params['kwargs'].items():
            if _key not in _all_params:
                raise ApiTypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method data_job_sources_download" % _key
                )
            _params[_key] = _val
        del _params['kwargs']

        _collection_formats = {}

        # process the path parameters
        _path_params = {}
        if _params['team_name']:
            _path_params['team_name'] = _params['team_name']

        if _params['job_name']:
            _path_params['job_name'] = _params['job_name']


        # process the query parameters
        _query_params = []
        # process the header parameters
        _header_params = dict(_params.get('_headers', {}))
        # process the form parameters
        _form_params = []
        _files = {}
        # process the body parameter
        _body_params = None
        # set the HTTP header `Accept`
        _header_params['Accept'] = self.api_client.select_header_accept(
            ['application/octet-stream', 'application/json'])  # noqa: E501

        # authentication setting
        _auth_settings = ['bearerAuth']  # noqa: E501

        _response_types_map = {
            '200': "bytearray",
            '400': "Error",
            '404': "Error",
        }

        return self.api_client.call_api(
            '/data-jobs/for-team/{team_name}/jobs/{job_name}/sources', 'GET',
            _path_params,
            _query_params,
            _header_params,
            body=_body_params,
            post_params=_form_params,
            files=_files,
            response_types_map=_response_types_map,
            auth_settings=_auth_settings,
            async_req=_params.get('async_req'),
            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
            _preload_content=_params.get('_preload_content', True),
            _request_timeout=_params.get('_request_timeout'),
            collection_formats=_collection_formats,
            _request_auth=_params.get('_request_auth'))

    @validate_arguments
    def sources_delete(self, team_name : Annotated[StrictStr, Field(..., description="Team Name")], job_name : Annotated[StrictStr, Field(..., description="Data Job Name.")], reason : Annotated[Optional[StrictStr], Field(description="The reason for executing the request")] = None, **kwargs) -> None:  # noqa: E501
        """Delete Data Job source.  # noqa: E501

        <i>(Introduced in v1.0)</i> | Data Job Source is persisted in version control.<br> Delete removes the Data Job Source code.   # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True

        >>> thread = api.sources_delete(team_name, job_name, reason, async_req=True)
        >>> result = thread.get()

        :param team_name: Team Name (required)
        :type team_name: str
        :param job_name: Data Job Name. (required)
        :type job_name: str
        :param reason: The reason for executing the request
        :type reason: str
        :param async_req: Whether to execute the request asynchronously.
        :type async_req: bool, optional
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return: Returns the result object.
                 If the method is called asynchronously,
                 returns the request thread.
        :rtype: None
        """
        kwargs['_return_http_data_only'] = True
        if '_preload_content' in kwargs:
            raise ValueError("Error! Please call the sources_delete_with_http_info method with `_preload_content` instead and obtain raw data from ApiResponse.raw_data")
        return self.sources_delete_with_http_info(team_name, job_name, reason, **kwargs)  # noqa: E501

    @validate_arguments
    def sources_delete_with_http_info(self, team_name : Annotated[StrictStr, Field(..., description="Team Name")], job_name : Annotated[StrictStr, Field(..., description="Data Job Name.")], reason : Annotated[Optional[StrictStr], Field(description="The reason for executing the request")] = None, **kwargs) -> ApiResponse:  # noqa: E501
        """Delete Data Job source.  # noqa: E501

        <i>(Introduced in v1.0)</i> | Data Job Source is persisted in version control.<br> Delete removes the Data Job Source code.   # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True

        >>> thread = api.sources_delete_with_http_info(team_name, job_name, reason, async_req=True)
        >>> result = thread.get()

        :param team_name: Team Name (required)
        :type team_name: str
        :param job_name: Data Job Name. (required)
        :type job_name: str
        :param reason: The reason for executing the request
        :type reason: str
        :param async_req: Whether to execute the request asynchronously.
        :type async_req: bool, optional
        :param _preload_content: if False, the ApiResponse.data will
                                 be set to none and raw_data will store the 
                                 HTTP response body without reading/decoding.
                                 Default is True.
        :type _preload_content: bool, optional
        :param _return_http_data_only: response data instead of ApiResponse
                                       object with status code, headers, etc
        :type _return_http_data_only: bool, optional
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the authentication
                              in the spec for a single request.
        :type _request_auth: dict, optional
        :type _content_type: string, optional: force content-type for the request
        :return: Returns the result object.
                 If the method is called asynchronously,
                 returns the request thread.
        :rtype: None
        """

        _params = locals()

        _all_params = [
            'team_name',
            'job_name',
            'reason'
        ]
        _all_params.extend(
            [
                'async_req',
                '_return_http_data_only',
                '_preload_content',
                '_request_timeout',
                '_request_auth',
                '_content_type',
                '_headers'
            ]
        )

        # validate the arguments
        for _key, _val in _params['kwargs'].items():
            if _key not in _all_params:
                raise ApiTypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method sources_delete" % _key
                )
            _params[_key] = _val
        del _params['kwargs']

        _collection_formats = {}

        # process the path parameters
        _path_params = {}
        if _params['team_name']:
            _path_params['team_name'] = _params['team_name']

        if _params['job_name']:
            _path_params['job_name'] = _params['job_name']


        # process the query parameters
        _query_params = []
        if _params.get('reason') is not None:  # noqa: E501
            _query_params.append(('reason', _params['reason']))

        # process the header parameters
        _header_params = dict(_params.get('_headers', {}))
        # process the form parameters
        _form_params = []
        _files = {}
        # process the body parameter
        _body_params = None
        # set the HTTP header `Accept`
        _header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # authentication setting
        _auth_settings = ['bearerAuth']  # noqa: E501

        _response_types_map = {}

        return self.api_client.call_api(
            '/data-jobs/for-team/{team_name}/jobs/{job_name}/sources', 'DELETE',
            _path_params,
            _query_params,
            _header_params,
            body=_body_params,
            post_params=_form_params,
            files=_files,
            response_types_map=_response_types_map,
            auth_settings=_auth_settings,
            async_req=_params.get('async_req'),
            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
            _preload_content=_params.get('_preload_content', True),
            _request_timeout=_params.get('_request_timeout'),
            collection_formats=_collection_formats,
            _request_auth=_params.get('_request_auth'))

    @validate_arguments
    def sources_upload(self, team_name : Annotated[StrictStr, Field(..., description="Team Name")], job_name : Annotated[StrictStr, Field(..., description="Data Job Name.")], body : Union[StrictBytes, StrictStr], reason : Annotated[Optional[StrictStr], Field(description="The reason for executing the request")] = None, **kwargs) -> DataJobVersion:  # noqa: E501
        """Upload Data Job source code. | (Stable)  # noqa: E501

        <i>(Introduced in v1.0)</i> | Uploads the Data Job source code and returns its version. Upload is persisted in source (Git) repository, so that all code deployed is versioned. The format of the payload is expected to be a ZIP archive, where the directory content can be found. <br>Example:<br> <br> If zip is <br> foo/file.txt<br> foo/nested_dir/file2.txt<br> <br>then data job dir uploaded will look like <br> job-name/file.txt<br> job-name/nested_dir/file2.txt<br>   # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True

        >>> thread = api.sources_upload(team_name, job_name, body, reason, async_req=True)
        >>> result = thread.get()

        :param team_name: Team Name (required)
        :type team_name: str
        :param job_name: Data Job Name. (required)
        :type job_name: str
        :param body: (required)
        :type body: bytearray
        :param reason: The reason for executing the request
        :type reason: str
        :param async_req: Whether to execute the request asynchronously.
        :type async_req: bool, optional
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return: Returns the result object.
                 If the method is called asynchronously,
                 returns the request thread.
        :rtype: DataJobVersion
        """
        kwargs['_return_http_data_only'] = True
        if '_preload_content' in kwargs:
            raise ValueError("Error! Please call the sources_upload_with_http_info method with `_preload_content` instead and obtain raw data from ApiResponse.raw_data")
        return self.sources_upload_with_http_info(team_name, job_name, body, reason, **kwargs)  # noqa: E501

    @validate_arguments
    def sources_upload_with_http_info(self, team_name : Annotated[StrictStr, Field(..., description="Team Name")], job_name : Annotated[StrictStr, Field(..., description="Data Job Name.")], body : Union[StrictBytes, StrictStr], reason : Annotated[Optional[StrictStr], Field(description="The reason for executing the request")] = None, **kwargs) -> ApiResponse:  # noqa: E501
        """Upload Data Job source code. | (Stable)  # noqa: E501

        <i>(Introduced in v1.0)</i> | Uploads the Data Job source code and returns its version. Upload is persisted in source (Git) repository, so that all code deployed is versioned. The format of the payload is expected to be a ZIP archive, where the directory content can be found. <br>Example:<br> <br> If zip is <br> foo/file.txt<br> foo/nested_dir/file2.txt<br> <br>then data job dir uploaded will look like <br> job-name/file.txt<br> job-name/nested_dir/file2.txt<br>   # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True

        >>> thread = api.sources_upload_with_http_info(team_name, job_name, body, reason, async_req=True)
        >>> result = thread.get()

        :param team_name: Team Name (required)
        :type team_name: str
        :param job_name: Data Job Name. (required)
        :type job_name: str
        :param body: (required)
        :type body: bytearray
        :param reason: The reason for executing the request
        :type reason: str
        :param async_req: Whether to execute the request asynchronously.
        :type async_req: bool, optional
        :param _preload_content: if False, the ApiResponse.data will
                                 be set to none and raw_data will store the 
                                 HTTP response body without reading/decoding.
                                 Default is True.
        :type _preload_content: bool, optional
        :param _return_http_data_only: response data instead of ApiResponse
                                       object with status code, headers, etc
        :type _return_http_data_only: bool, optional
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the authentication
                              in the spec for a single request.
        :type _request_auth: dict, optional
        :type _content_type: string, optional: force content-type for the request
        :return: Returns the result object.
                 If the method is called asynchronously,
                 returns the request thread.
        :rtype: tuple(DataJobVersion, status_code(int), headers(HTTPHeaderDict))
        """

        _params = locals()

        _all_params = [
            'team_name',
            'job_name',
            'body',
            'reason'
        ]
        _all_params.extend(
            [
                'async_req',
                '_return_http_data_only',
                '_preload_content',
                '_request_timeout',
                '_request_auth',
                '_content_type',
                '_headers'
            ]
        )

        # validate the arguments
        for _key, _val in _params['kwargs'].items():
            if _key not in _all_params:
                raise ApiTypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method sources_upload" % _key
                )
            _params[_key] = _val
        del _params['kwargs']

        _collection_formats = {}

        # process the path parameters
        _path_params = {}
        if _params['team_name']:
            _path_params['team_name'] = _params['team_name']

        if _params['job_name']:
            _path_params['job_name'] = _params['job_name']


        # process the query parameters
        _query_params = []
        if _params.get('reason') is not None:  # noqa: E501
            _query_params.append(('reason', _params['reason']))

        # process the header parameters
        _header_params = dict(_params.get('_headers', {}))
        # process the form parameters
        _form_params = []
        _files = {}
        # process the body parameter
        _body_params = None
        if _params['body'] is not None:
            _body_params = _params['body']
            # convert to byte array if the input is a file name (str)
            if isinstance(_body_params, str):
                with io.open(_body_params, "rb") as _fp:
                   _body_params_from_file = _fp.read()
                _body_params = _body_params_from_file

        # set the HTTP header `Accept`
        _header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # set the HTTP header `Content-Type`
        _content_types_list = _params.get('_content_type',
            self.api_client.select_header_content_type(
                ['application/octet-stream']))
        if _content_types_list:
                _header_params['Content-Type'] = _content_types_list

        # authentication setting
        _auth_settings = ['bearerAuth']  # noqa: E501

        _response_types_map = {
            '200': "DataJobVersion",
            '400': "Error",
        }

        return self.api_client.call_api(
            '/data-jobs/for-team/{team_name}/jobs/{job_name}/sources', 'POST',
            _path_params,
            _query_params,
            _header_params,
            body=_body_params,
            post_params=_form_params,
            files=_files,
            response_types_map=_response_types_map,
            auth_settings=_auth_settings,
            async_req=_params.get('async_req'),
            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
            _preload_content=_params.get('_preload_content', True),
            _request_timeout=_params.get('_request_timeout'),
            collection_formats=_collection_formats,
            _request_auth=_params.get('_request_auth'))
