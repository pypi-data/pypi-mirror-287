{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Any\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import json\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from pathlib import Path\n",
    "from utils.read_jsonl_data import read_jsonl_data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SEED = 12345\n",
    "val_size = 0.05\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "# Train data\n",
    "TRAIN_DATA_DIR = Path(\"data/Толока Персона Чат\")\n",
    "gk_1_500_path = TRAIN_DATA_DIR / \"TolokaPersonaChat_gk_1_500.jsonl\"\n",
    "gk_test_1_500_path = TRAIN_DATA_DIR / \"TolokaPersonaChat_1_500_gk_test.jsonl\"\n",
    "test_stipa_path = TRAIN_DATA_DIR / \"gk(test)Stipa.jsonl\"\n",
    "genderized_gk_test_v2_path = TRAIN_DATA_DIR / \"TolokaPersonaChat_genderized_gk(test)v2.jsonl\"\n",
    "\n",
    "# Test data\n",
    "TEST_DATA_DIR = Path(\"data/test\")\n",
    "all_dialogs_path = TEST_DATA_DIR / \"all_dialogs.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-small-chitchat\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-small-chitchat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(\n",
    "    data: List[Dict[str, str]],\n",
    "    val_size: int = val_size,\n",
    "    shuffle: bool = True,\n",
    ") -> Tuple[List[Dict[str, str]], List[Dict[str, str]]]:\n",
    "    if shuffle:\n",
    "        random.shuffle(data)\n",
    "    val_len = int(val_size * len(data))\n",
    "    data_train, data_val = data[:-val_len], data[-val_len:]\n",
    "    return data_train, data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_1_500_data = read_jsonl_data(gk_1_500_path)\n",
    "gk_test_1_500_data = read_jsonl_data(gk_test_1_500_path)\n",
    "test_stipa_data = read_jsonl_data(test_stipa_path)\n",
    "genderized_gk_test_v2_data = read_jsonl_data(genderized_gk_test_v2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_1_500_data_train, gk_1_500_data_val = train_val_split(gk_1_500_data, val_size, True)\n",
    "gk_test_1_500_data_train, gk_test_1_500_data_val = train_val_split(gk_test_1_500_data, val_size, True)\n",
    "test_stipa_data_train, test_stipa_data_val = train_val_split(test_stipa_data, val_size, True)\n",
    "genderized_gk_test_v2_data_train, genderized_gk_test_v2_data_val = train_val_split(genderized_gk_test_v2_data, val_size, True)\n",
    "\n",
    "data_train = gk_1_500_data_train + gk_test_1_500_data_train + test_stipa_data_train + genderized_gk_test_v2_data_train\n",
    "data_val = gk_1_500_data_val + gk_test_1_500_data_val + test_stipa_data_val + genderized_gk_test_v2_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2838, 147)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train), len(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def compress_consecutive_statements(dialog: List[Dict[str, Any]]):\n",
    "    # Сжимаем все подряд идущие высказывания одного спикера\n",
    "    compressed_dialog: List[Dict[str, Any]] = list()\n",
    "    \n",
    "    last_person: int = dialog[0]['person']\n",
    "    whole_text = [dialog[0]['text']]\n",
    "    for message in dialog[1:]:\n",
    "        text, person = message['text'], message['person']\n",
    "\n",
    "        if last_person == person:\n",
    "            whole_text.append(text)\n",
    "        else:\n",
    "            new_message = {\n",
    "                \"person\": last_person,\n",
    "                \"text\": \" \".join(whole_text)\n",
    "            }\n",
    "            compressed_dialog.append(new_message)\n",
    "            last_person = person\n",
    "            whole_text = [text]\n",
    "    \n",
    "    new_message = {\n",
    "        \"person\": last_person,\n",
    "        \"text\": \" \".join(whole_text)\n",
    "    }\n",
    "    compressed_dialog.append(new_message)\n",
    "    \n",
    "    return compressed_dialog\n",
    "\n",
    "def make_pairs(\n",
    "    data: List[Dict[str, List[Dict[str, Any]]]],\n",
    "    tokenizer: T5Tokenizer,\n",
    "    max_history_tokens: int,\n",
    "    max_history_messages: int = 3,\n",
    "    # max_target_tokens: int,\n",
    ") -> List[Tuple[str, str]]:\n",
    "    # Все пары \"история общения -> ответ\"\n",
    "    pairs: List[Tuple[str, str]] = list()\n",
    "    \n",
    "    for data_item in tqdm(data):\n",
    "        # Пары \"история общения -> ответ\" в рамках одного диалога\n",
    "        dialog_pairs: List[Tuple[List[str], str]] = list()\n",
    "\n",
    "        # Сжимаем все подряд идущие высказывания одного спикера\n",
    "        dialog = compress_consecutive_statements(data_item['dialog'])\n",
    "        \n",
    "        historical_text = [dialog[0]['text']]\n",
    "        for message in dialog[1:]:\n",
    "            text = message['text']\n",
    "            for history_messages_len in range(1, max_history_messages+1):\n",
    "                if len(historical_text) >= history_messages_len:\n",
    "                    dialog_pairs.append((historical_text[-history_messages_len:], text))\n",
    "            \n",
    "            offset = 0\n",
    "            historical_text = dialog_pairs[-1][0][offset:] + [text]\n",
    "            # historical_text = \"</s>\".join(historical_text)\n",
    "            \n",
    "            while len(tokenizer(\"</s>\".join(historical_text)).input_ids) > max_history_tokens:\n",
    "                offset += 1\n",
    "                historical_text = dialog_pairs[-1][0][offset:] + [text]\n",
    "                # historical_text = \"</s>\".join(historical_text)\n",
    "        \n",
    "        pairs.extend(dialog_pairs)\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8fc97ea5a44e688dac779b97f91c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2838 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b1c1255ebd4fd691fa7324de684723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161496 7962\n"
     ]
    }
   ],
   "source": [
    "pairs_train = make_pairs(data_train, tokenizer, 512, 4)\n",
    "pairs_val = make_pairs(data_val, tokenizer, 512, 4)\n",
    "print(len(pairs_train), len(pairs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pairs_train = pd.DataFrame([(\"</s>\".join(p[0]), p[1]) for p in pairs_train]) # .drop_duplicates()\n",
    "pairs_val = pd.DataFrame([(\"</s>\".join(p[0]), p[1]) for p in pairs_val]) # .drop_duplicates()\n",
    "\n",
    "pairs_train = pairs_train[~pairs_train.duplicated()]\n",
    "pairs_train = pairs_train[~(pairs_train[0].isin(pairs_val[0]) & pairs_train[1].isin(pairs_val[1]))]\n",
    "pairs_val = pairs_val.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "# raw_model = 'cointegrated/rut5-base-multitask' \n",
    "# model = T5ForConditionalGeneration.from_pretrained(raw_model).cuda();\n",
    "# tokenizer = T5Tokenizer.from_pretrained(raw_model)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "raw_model = \"cointegrated/rut5-small-chitchat\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(raw_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(raw_model).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.1)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16015923e4b84a4dbd65301c8dc061a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.824 | val loss 3.831\n",
      "step 200 | train loss 3.985 | val loss 3.628\n",
      "step 400 | train loss 3.867 | val loss 3.544\n",
      "step 600 | train loss 3.812 | val loss 3.496\n",
      "step 800 | train loss 3.772 | val loss 3.468\n",
      "step 1000 | train loss 3.717 | val loss 3.442\n",
      "step 1200 | train loss 3.71 | val loss 3.422\n",
      "step 1400 | train loss 3.664 | val loss 3.406\n",
      "step 1600 | train loss 3.643 | val loss 3.391\n",
      "step 1800 | train loss 3.637 | val loss 3.38\n",
      "step 2000 | train loss 3.642 | val loss 3.365\n",
      "EPOCH 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f49513f94664410894aee77c6be640b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.635 | val loss 3.362\n",
      "step 200 | train loss 3.603 | val loss 3.352\n",
      "step 400 | train loss 3.602 | val loss 3.344\n",
      "step 600 | train loss 3.582 | val loss 3.333\n",
      "step 800 | train loss 3.559 | val loss 3.325\n",
      "step 1000 | train loss 3.567 | val loss 3.318\n",
      "step 1200 | train loss 3.56 | val loss 3.313\n",
      "step 1400 | train loss 3.529 | val loss 3.302\n",
      "step 1600 | train loss 3.554 | val loss 3.296\n",
      "step 1800 | train loss 3.535 | val loss 3.292\n",
      "step 2000 | train loss 3.514 | val loss 3.285\n",
      "EPOCH 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcce22bfe2794ab49bfdc00dc693e39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.51 | val loss 3.283\n",
      "step 200 | train loss 3.516 | val loss 3.278\n",
      "step 400 | train loss 3.508 | val loss 3.275\n",
      "step 600 | train loss 3.486 | val loss 3.27\n",
      "step 800 | train loss 3.489 | val loss 3.264\n",
      "step 1000 | train loss 3.472 | val loss 3.257\n",
      "step 1200 | train loss 3.478 | val loss 3.252\n",
      "step 1400 | train loss 3.452 | val loss 3.254\n",
      "step 1600 | train loss 3.465 | val loss 3.245\n",
      "step 1800 | train loss 3.448 | val loss 3.241\n",
      "step 2000 | train loss 3.433 | val loss 3.237\n",
      "EPOCH 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016d6cf674a04c51a224928de3061eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.438 | val loss 3.237\n",
      "step 200 | train loss 3.439 | val loss 3.232\n",
      "step 400 | train loss 3.425 | val loss 3.228\n",
      "step 600 | train loss 3.425 | val loss 3.224\n",
      "step 800 | train loss 3.441 | val loss 3.223\n",
      "step 1000 | train loss 3.403 | val loss 3.222\n",
      "step 1200 | train loss 3.42 | val loss 3.218\n",
      "step 1400 | train loss 3.4 | val loss 3.211\n",
      "step 1600 | train loss 3.38 | val loss 3.212\n",
      "step 1800 | train loss 3.402 | val loss 3.207\n",
      "step 2000 | train loss 3.411 | val loss 3.207\n",
      "EPOCH 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e805ad6730a48fa89906f733d3dc510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.406 | val loss 3.204\n",
      "step 200 | train loss 3.387 | val loss 3.207\n",
      "step 400 | train loss 3.384 | val loss 3.201\n",
      "step 600 | train loss 3.393 | val loss 3.198\n",
      "step 800 | train loss 3.357 | val loss 3.194\n",
      "step 1000 | train loss 3.371 | val loss 3.194\n",
      "step 1200 | train loss 3.364 | val loss 3.19\n",
      "step 1400 | train loss 3.364 | val loss 3.19\n",
      "step 1600 | train loss 3.354 | val loss 3.189\n",
      "step 1800 | train loss 3.357 | val loss 3.18\n",
      "step 2000 | train loss 3.332 | val loss 3.181\n",
      "EPOCH 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549e7d4d6c874f4db26aaa0e8a0932eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.34 | val loss 3.179\n",
      "step 200 | train loss 3.329 | val loss 3.18\n",
      "step 400 | train loss 3.326 | val loss 3.179\n",
      "step 600 | train loss 3.334 | val loss 3.177\n",
      "step 800 | train loss 3.336 | val loss 3.173\n",
      "step 1000 | train loss 3.339 | val loss 3.174\n",
      "step 1200 | train loss 3.308 | val loss 3.17\n",
      "step 1400 | train loss 3.314 | val loss 3.167\n",
      "step 1600 | train loss 3.317 | val loss 3.165\n",
      "step 1800 | train loss 3.32 | val loss 3.164\n",
      "step 2000 | train loss 3.329 | val loss 3.163\n",
      "EPOCH 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da869e9fb0964111b0b3008a507eb9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.33 | val loss 3.165\n",
      "step 200 | train loss 3.295 | val loss 3.163\n",
      "step 400 | train loss 3.303 | val loss 3.161\n",
      "step 600 | train loss 3.28 | val loss 3.161\n",
      "step 800 | train loss 3.31 | val loss 3.159\n",
      "step 1000 | train loss 3.29 | val loss 3.154\n",
      "step 1200 | train loss 3.302 | val loss 3.157\n",
      "step 1400 | train loss 3.278 | val loss 3.156\n",
      "step 1600 | train loss 3.278 | val loss 3.153\n",
      "step 1800 | train loss 3.291 | val loss 3.151\n",
      "step 2000 | train loss 3.276 | val loss 3.151\n",
      "EPOCH 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9263043af183482b9a56603f5fad31bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.272 | val loss 3.152\n",
      "step 200 | train loss 3.27 | val loss 3.148\n",
      "step 400 | train loss 3.29 | val loss 3.145\n",
      "step 600 | train loss 3.238 | val loss 3.149\n",
      "step 800 | train loss 3.255 | val loss 3.146\n",
      "step 1000 | train loss 3.266 | val loss 3.144\n",
      "step 1200 | train loss 3.267 | val loss 3.144\n",
      "step 1400 | train loss 3.234 | val loss 3.142\n",
      "step 1600 | train loss 3.26 | val loss 3.141\n",
      "step 1800 | train loss 3.266 | val loss 3.137\n",
      "step 2000 | train loss 3.245 | val loss 3.138\n",
      "EPOCH 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c9a32d60494ba4b91956809e050efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.247 | val loss 3.139\n",
      "step 200 | train loss 3.239 | val loss 3.14\n",
      "step 400 | train loss 3.232 | val loss 3.138\n",
      "step 600 | train loss 3.235 | val loss 3.138\n",
      "step 800 | train loss 3.238 | val loss 3.132\n",
      "step 1000 | train loss 3.237 | val loss 3.134\n",
      "step 1200 | train loss 3.211 | val loss 3.135\n",
      "step 1400 | train loss 3.199 | val loss 3.136\n",
      "step 1600 | train loss 3.242 | val loss 3.13\n",
      "step 1800 | train loss 3.235 | val loss 3.132\n",
      "step 2000 | train loss 3.23 | val loss 3.132\n",
      "EPOCH 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aae4977e74c40c29aad8683d7b43732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.221 | val loss 3.13\n",
      "step 200 | train loss 3.216 | val loss 3.126\n",
      "step 400 | train loss 3.209 | val loss 3.129\n",
      "step 600 | train loss 3.238 | val loss 3.127\n",
      "step 800 | train loss 3.204 | val loss 3.125\n",
      "step 1000 | train loss 3.204 | val loss 3.128\n",
      "step 1200 | train loss 3.194 | val loss 3.126\n",
      "step 1400 | train loss 3.186 | val loss 3.125\n",
      "step 1600 | train loss 3.186 | val loss 3.125\n",
      "step 1800 | train loss 3.206 | val loss 3.125\n",
      "step 2000 | train loss 3.195 | val loss 3.12\n",
      "EPOCH 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fc7530f6f2409696ee75442da2b92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.199 | val loss 3.125\n",
      "step 200 | train loss 3.187 | val loss 3.122\n",
      "step 400 | train loss 3.186 | val loss 3.125\n",
      "step 600 | train loss 3.187 | val loss 3.124\n",
      "step 800 | train loss 3.188 | val loss 3.117\n",
      "step 1000 | train loss 3.196 | val loss 3.118\n",
      "step 1200 | train loss 3.171 | val loss 3.123\n",
      "step 1400 | train loss 3.157 | val loss 3.12\n",
      "step 1600 | train loss 3.181 | val loss 3.12\n",
      "step 1800 | train loss 3.163 | val loss 3.123\n",
      "step 2000 | train loss 3.18 | val loss 3.118\n",
      "EPOCH 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4e62267f9f4a4db5c845b12b6bbacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.18 | val loss 3.115\n",
      "step 200 | train loss 3.18 | val loss 3.116\n",
      "step 400 | train loss 3.165 | val loss 3.115\n",
      "step 600 | train loss 3.147 | val loss 3.118\n",
      "step 800 | train loss 3.169 | val loss 3.117\n",
      "step 1000 | train loss 3.147 | val loss 3.116\n",
      "step 1200 | train loss 3.151 | val loss 3.116\n",
      "step 1400 | train loss 3.157 | val loss 3.118\n",
      "step 1600 | train loss 3.138 | val loss 3.113\n",
      "step 1800 | train loss 3.135 | val loss 3.112\n",
      "step 2000 | train loss 3.173 | val loss 3.112\n",
      "EPOCH 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b12957d829c400ebe0cc986988d835b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.176 | val loss 3.112\n",
      "step 200 | train loss 3.131 | val loss 3.113\n",
      "step 400 | train loss 3.128 | val loss 3.113\n",
      "step 600 | train loss 3.16 | val loss 3.113\n",
      "step 800 | train loss 3.14 | val loss 3.11\n",
      "step 1000 | train loss 3.148 | val loss 3.113\n",
      "step 1200 | train loss 3.134 | val loss 3.114\n",
      "step 1400 | train loss 3.119 | val loss 3.113\n",
      "step 1600 | train loss 3.15 | val loss 3.107\n",
      "step 1800 | train loss 3.115 | val loss 3.108\n",
      "step 2000 | train loss 3.113 | val loss 3.11\n",
      "EPOCH 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ceaa4becacf42aba24f62e102ea23f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.114 | val loss 3.107\n",
      "step 200 | train loss 3.107 | val loss 3.107\n",
      "step 400 | train loss 3.13 | val loss 3.105\n",
      "step 600 | train loss 3.128 | val loss 3.108\n",
      "step 800 | train loss 3.122 | val loss 3.105\n",
      "step 1000 | train loss 3.102 | val loss 3.107\n",
      "step 1200 | train loss 3.118 | val loss 3.109\n",
      "step 1400 | train loss 3.127 | val loss 3.105\n",
      "step 1600 | train loss 3.096 | val loss 3.106\n",
      "step 1800 | train loss 3.119 | val loss 3.105\n",
      "step 2000 | train loss 3.092 | val loss 3.106\n",
      "EPOCH 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a605f6f2668b4551adf33d315dd45a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | train loss 3.101 | val loss 3.104\n",
      "step 200 | train loss 3.094 | val loss 3.104\n",
      "step 400 | train loss 3.112 | val loss 3.106\n",
      "step 600 | train loss 3.1 | val loss 3.106\n",
      "step 800 | train loss 3.096 | val loss 3.106\n",
      "step 1000 | train loss 3.083 | val loss 3.106\n",
      "step 1200 | train loss 3.101 | val loss 3.102\n",
      "step 1400 | train loss 3.085 | val loss 3.105\n",
      "step 1600 | train loss 3.073 | val loss 3.102\n",
      "step 1800 | train loss 3.093 | val loss 3.099\n",
      "step 2000 | train loss 3.095 | val loss 3.102\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import trange\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 24 # сколько примеров показываем модели за один шаг\n",
    "report_steps = 200  # раз в сколько шагов печатаем результат\n",
    "epochs = 15  # сколько раз мы покажем данные модели\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(pairs, tokenizer, model) -> float:\n",
    "    eval_losses = list()\n",
    "    model.eval()\n",
    "\n",
    "    pairs = pairs.sample(frac=1)\n",
    "    for i in range(0, int(len(pairs) / batch_size)):\n",
    "        batch = pairs.values[i * batch_size: (i + 1) * batch_size]\n",
    "        # кодируем вопрос и ответ \n",
    "        x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=\"longest\").to(model.device)\n",
    "        y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=\"longest\").to(model.device)\n",
    "        # -100 - специальное значение, позволяющее не учитывать токены\n",
    "        y.input_ids[y.input_ids == 0] = -100\n",
    "        # вычисляем функцию потерь\n",
    "        loss = model(\n",
    "            input_ids=x.input_ids,\n",
    "            attention_mask=x.attention_mask,\n",
    "            labels=y.input_ids,\n",
    "            decoder_attention_mask=y.attention_mask,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "        eval_losses.append(loss.item())\n",
    "    \n",
    "    return np.mean(eval_losses)\n",
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "\n",
    "best_model = None\n",
    "best_loss = 1000000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('EPOCH', epoch)\n",
    "    pairs_train = pairs_train.sample(frac=1)\n",
    "    for i in trange(0, int(len(pairs_train) / batch_size)):\n",
    "        batch = pairs_train.values[i * batch_size: (i + 1) * batch_size]\n",
    "        # кодируем вопрос и ответ \n",
    "        x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=\"longest\").to(model.device)\n",
    "        y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=\"longest\").to(model.device)\n",
    "        # -100 - специальное значение, позволяющее не учитывать токены\n",
    "        y.input_ids[y.input_ids == 0] = -100\n",
    "        # вычисляем функцию потерь\n",
    "        loss = model(\n",
    "            input_ids=x.input_ids,\n",
    "            attention_mask=x.attention_mask,\n",
    "            labels=y.input_ids,\n",
    "            decoder_attention_mask=y.attention_mask,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "        # делаем шаг градиентного спуска\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # печатаем скользящее среднее значение функции потерь\n",
    "        losses.append(loss.item())\n",
    "        if i % report_steps == 0:\n",
    "            val_loss = eval(pairs_val, tokenizer, model)\n",
    "            print('step', i, '| train loss', np.round(np.mean(losses[-report_steps:]), 3), '| val loss', np.round(val_loss, 3))\n",
    "            if val_loss < best_loss:\n",
    "                best_model = model\n",
    "                best_loss = val_loss\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = epoch * int(len(pairs_train) / batch_size) + i\n",
    "save_dir = Path(\"experiments/exp1-t5-small-chitchat-finetuning\") / f\"checkpoints/{step}_steps/\"\n",
    "model.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"experiments/exp1-t5-small-chitchat-finetuning\") / \"checkpoints/best_model\"\n",
    "best_model.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0993898600435106"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bot1: Привет!\n",
      "bot0: Привет, как тебя зовут?\n",
      "bot1: Меня зовут Евгений. Я учитель\n",
      "bot0: Чем занимаешься?\n",
      "bot1: Я работаю инженером. Чем увлекаешься?\n",
      "bot0: Я люблю готовить, а ты?\n",
      "bot1: Я люблю читать. А ты?\n",
      "bot0: Я очень люблю готовить, но это не интересно. А у тебя есть хобби?\n",
      "bot1: Да, я люблю готовить. Любишь путешествовать?\n",
      "bot0: Да, я люблю путешествовать. А ты?\n",
      "bot1: Это здорово. Я тоже люблю путешествовать\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "@torch.no_grad()\n",
    "def answer(history_text: str, model) -> str:\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(history_text, return_tensors='pt')\n",
    "    hypotheses = model.generate(\n",
    "        **{k: v.to(model.device) for k, v in inputs.items()},\n",
    "        do_sample=True,\n",
    "        top_p=0.5,\n",
    "        num_return_sequences=1,\n",
    "        repetition_penalty=1.5,\n",
    "        max_length=1024,\n",
    "    )\n",
    "    return tokenizer.decode(hypotheses[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "history_text = [\"Привет!\"]\n",
    "print(\"bot1:\", history_text[0])\n",
    "\n",
    "for idx in range(10):\n",
    "    history_tmp = \"</s>\".join(history_text[-3:])\n",
    "    text = answer(history_tmp, best_model).replace(\"<pad>\", \"\").strip()\n",
    "    print(f\"bot{idx % 2}:\", text)\n",
    "    \n",
    "    history_text.append(text)\n",
    "    time.sleep(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch=3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
