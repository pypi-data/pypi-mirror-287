{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fcc525-8149-451e-b9f6-f1656a406d39",
   "metadata": {},
   "source": [
    "!pip install burr"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5f7d4516-c5e1-4889-abed-155645c41d9d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Traces/Spans\n",
    "\n",
    "This walks through the traces/spans example. You can see the code in [application.py](application.py).\n",
    "\n",
    "To ground this, you can see an example action implementation (from `application.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82986ee3-3662-4a74-b4d1-cced1caa1095",
   "metadata": {},
   "source": [
    "from burr.core import action, State\n",
    "from burr.visibility import TracerFactory\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "@action(reads=[\"prompt\"], writes=[\"mode\"])\n",
    "def choose_mode(state: State, __tracer: TracerFactory) -> Tuple[dict, State]:\n",
    "    with __tracer(\"generate_prompt\"):\n",
    "        prompt = (\n",
    "            f\"You are a chatbot. You've been prompted this: {state['prompt']}. \"\n",
    "            f\"You have the capability of responding in the following modes: {', '.join(MODES)}. \"\n",
    "            \"Please respond with *only* a single word representing the mode that most accurately \"\n",
    "            \"corresponds to the prompt. Fr instance, if the prompt is 'draw a picture of a cat', \"\n",
    "            \"the mode would be 'generate_image'. If the prompt is 'what is the capital of France', the mode would be 'answer_question'.\"\n",
    "            \"If none of these modes apply, please respond with 'unknown'.\"\n",
    "        )\n",
    "    with __tracer(\"query_openai\", span_dependencies=[\"generate_prompt\"]):\n",
    "        with __tracer(\"create_openai_client\"):\n",
    "            client = _get_openai_client()\n",
    "        with __tracer(\"query_openai\"):\n",
    "            result = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "            )\n",
    "    with __tracer(\"process_openai_response\", span_dependencies=[\"query_openai\"]):\n",
    "        content = result.choices[0].message.content\n",
    "        mode = content.lower()\n",
    "        if mode not in MODES:\n",
    "            mode = \"unknown\"\n",
    "        result = {\"mode\": mode}\n",
    "    return result, state.update(**result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a07bdcf3-94f4-47d0-8ec3-00d3c7ee8c8d",
   "metadata": {},
   "source": [
    "# Running the code\n",
    "\n",
    "The following runs the application on a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba29bd1-3e59-4050-821c-8da44c2c583f",
   "metadata": {},
   "source": [
    "from application import application as tracing_and_spans_application"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db048ea6-dd1a-4088-93e3-508cb5d86c9d",
   "metadata": {},
   "source": [
    "app = tracing_and_spans_application()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c9586a-28a8-4f84-a2a2-6028a699371e",
   "metadata": {},
   "source": [
    "app.visualize(include_conditions=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58131e17-6f48-4d8b-b6c6-32605c30d62a",
   "metadata": {},
   "source": [
    "import pprint\n",
    "\n",
    "action, result, state = app.run(halt_after=[\"response\"], inputs={\"prompt\" : \"please write a haiku\"})\n",
    "pprint.pprint(result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c47d87b3-8d32-420b-ab75-acf2a7f6d2a9",
   "metadata": {},
   "source": [
    "# Viewing in UI\n",
    "\n",
    "The following cell gives you a link to the prior run in the UI. If you have not yet, run `burr` in your terminal to start the local tracking server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93cad8f7-9f0b-4b20-bc75-2adaca5bfde9",
   "metadata": {},
   "source": [
    "from IPython.display import Markdown\n",
    "url = f\"[Link to UI](http://localhost:7241/project/demo:tracing/{app.uid})\"\n",
    "Markdown(url)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
